# Qwen 2.5-VL Vision-Language Model Configuration
# ================================================

model_name: "Qwen/Qwen2.5-VL-7B-Instruct"

# Backbone settings
freeze_backbone: true
torch_dtype: "bfloat16"
device_map: "auto"
trust_remote_code: true

# Vision processing
min_pixels: 200704  # 256 * 28 * 28
max_pixels: 1003520  # 1280 * 28 * 28

# LoRA configuration
use_lora: true
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"

# Model dimensions (Qwen 2.5-VL-7B)
hidden_size: 3584
num_attention_heads: 28
num_hidden_layers: 28
intermediate_size: 18944
vocab_size: 151936
